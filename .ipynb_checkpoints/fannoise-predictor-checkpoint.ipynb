{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "EAP\n",
      "RG-AIEAP\n",
      "southeastasia\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# get existing workspace\n",
    "ws = Workspace(\n",
    "    subscription_id=\"b14cff6a-38c4-4aec-9335-b453f4d03339\",\n",
    "    resource_group=\"RG-AIEAP\",\n",
    "    workspace_name=\"EAP\",\n",
    ")\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = \"delta-experiment\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '20190903080554-4415.wav',\n",
       " 'azureml-models',\n",
       " 'fannoise-predictor.ipynb',\n",
       " 'fold1',\n",
       " 'fold2',\n",
       " 'fold3',\n",
       " 'fold4',\n",
       " 'fold5',\n",
       " 'model.h5',\n",
       " 'myenv.yml',\n",
       " 'samples-1.0.69',\n",
       " 'score.py',\n",
       " 'twocategories',\n",
       " 'wav-150bands-150frames-3channel']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Model.register(model_path = \"model.h5\",\\n    model_name = \"fannoise-predictor\",\\n    description = \"delta fannoise recognotion model\",\\n    workspace = ws)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "\"\"\"\n",
    "model = Model.register(model_path = \"model.h5\",\n",
    "    model_name = \"fannoise-predictor\",\n",
    "    description = \"delta fannoise recognotion model\",\n",
    "    workspace = ws)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fannoise-predictor \n",
      "Version: 1 \n",
      "Description: delta fannoise recognotion model\n"
     ]
    }
   ],
   "source": [
    "# displaying registered models\n",
    "models = ws.models\n",
    "for name, m in models.items():\n",
    "    print(\"Name:\", name,\"\\nVersion:\", m.version, \"\\nDescription:\", m.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import signal\n",
    "\n",
    "model = Model.get_model_path(model_name = 'fannoise-predictor', _workspace = ws)\n",
    "\n",
    "sample_audio = \"20190903080554-4415.wav\"\n",
    "\n",
    "n_bands = 150\n",
    "n_frames = 150\n",
    "sample_rate = 22050\n",
    "\n",
    "\n",
    "def read_audio(audio_path, target_fs=None, duration=4):\n",
    "    (audio, fs) = librosa.load(audio_path, sr=None, duration=duration)\n",
    "    # if this is not a mono sounds file\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "    return audio, fs\n",
    "\n",
    "def pad_trunc_seq_rewrite(x, max_len):\n",
    "    if x.shape[1] < max_len:\n",
    "        pad_shape = (x.shape[0], max_len - x.shape[1])\n",
    "        pad = np.ones(pad_shape) * np.log(1e-8)\n",
    "        x_new = np.hstack((x, pad))\n",
    "    # no pad necessary - truncate\n",
    "    else:\n",
    "        x_new = x[:, 0:max_len]\n",
    "    return x_new\n",
    "\n",
    "def extract_features(parent_dir, sub_dirs, bands, frames, file_ext=\"*.wav\"):\n",
    "    # 4 second clip with 50% window overlap with small offset to guarantee frames\n",
    "    n_window = int(sample_rate * 4. / frames * 2) - 4 * 2\n",
    "    # 50% overlap\n",
    "    n_overlap = int(n_window / 2.)\n",
    "    # Mel filter bank\n",
    "    melW = librosa.filters.mel(sr=sample_rate, n_fft=n_window, n_mels=bands, fmin=0., fmax=8000.)\n",
    "    # Hamming window\n",
    "    ham_win = np.hamming(n_window)\n",
    "    log_specgrams_list = []\n",
    "\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            # print(\"processing\", fn)\n",
    "            sound_clip, fn_fs = read_audio(fn, target_fs=sample_rate)\n",
    "            assert (int(fn_fs) == sample_rate)\n",
    "\n",
    "            if sound_clip.shape[0] < n_window:\n",
    "                print(\"File %s is shorter than window size - DISCARDING - look into making the window larger.\" % fn)\n",
    "                continue\n",
    "\n",
    "            # Skip corrupted wavs\n",
    "            if sound_clip.shape[0] == 0:\n",
    "                print(\"File %s is corrupted!\" % fn)\n",
    "                continue\n",
    "\n",
    "            # Compute spectrogram\n",
    "            [f, t, x] = signal.spectral.spectrogram(\n",
    "                x=sound_clip,\n",
    "                window=ham_win,\n",
    "                nperseg=n_window,\n",
    "                noverlap=n_overlap,\n",
    "                detrend=False,\n",
    "                return_onesided=True,\n",
    "                mode='magnitude')\n",
    "            x = np.dot(x.T, melW.T)\n",
    "            x = np.log(x + 1e-8)\n",
    "            x = x.astype(np.float32).T\n",
    "            x = pad_trunc_seq_rewrite(x, frames)\n",
    "\n",
    "            log_specgrams_list.append(x)\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams_list).reshape(len(log_specgrams_list), bands, frames, 1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    features = np.concatenate((features, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    for i in range(len(features)):\n",
    "        # first order difference, computed over 9-step window\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "        # for using 3 dimensional array to use ResNet and other frameworks\n",
    "        features[i, :, :, 2] = librosa.feature.delta(features[i, :, :, 1])\n",
    "\n",
    "    return np.array(features)  #, np.array(labels, dtype=np.int)\n",
    "\n",
    "\n",
    "features = extract_features(\".\", sample_audio, bands=n_bands, frames=n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "cnn = keras.models.load_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "y_prob = cnn.predict(features, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "defect_code = {2: \"Pass\", 3: \"Noise\", 4: \"Rpm\", 5: \"Vibration\"}\n",
    "\n",
    "print(defect_code[int(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "from azureml.core.model import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "n_bands = 150\n",
    "n_frames = 150\n",
    "sample_rate = 22050\n",
    "\n",
    "\n",
    "def read_audio(audio_path, target_fs=None, duration=4):\n",
    "    (audio, fs) = librosa.load(audio_path, sr=None, duration=duration)\n",
    "    # if this is not a mono sounds file\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "    return audio, fs\n",
    "\n",
    "def pad_trunc_seq_rewrite(x, max_len):\n",
    "    if x.shape[1] < max_len:\n",
    "        pad_shape = (x.shape[0], max_len - x.shape[1])\n",
    "        pad = np.ones(pad_shape) * np.log(1e-8)\n",
    "        x_new = np.hstack((x, pad))\n",
    "    # no pad necessary - truncate\n",
    "    else:\n",
    "        x_new = x[:, 0:max_len]\n",
    "    return x_new\n",
    "\n",
    "def extract_features(sample_audio, bands, frames, file_ext=\"*.wav\"):\n",
    "    # 4 second clip with 50% window overlap with small offset to guarantee frames\n",
    "    n_window = int(sample_rate * 4. / frames * 2) - 4 * 2\n",
    "    # 50% overlap\n",
    "    n_overlap = int(n_window / 2.)\n",
    "    # Mel filter bank\n",
    "    melW = librosa.filters.mel(sr=sample_rate, n_fft=n_window, n_mels=bands, fmin=0., fmax=8000.)\n",
    "    # Hamming window\n",
    "    ham_win = np.hamming(n_window)\n",
    "    log_specgrams_list = []\n",
    "\n",
    "\n",
    "    sound_clip, fn_fs = read_audio(sample_audio, target_fs=sample_rate)\n",
    "    assert (int(fn_fs) == sample_rate)\n",
    "\n",
    "    if sound_clip.shape[0] < n_window:\n",
    "        print(\"File %s is shorter than window size - DISCARDING - look into making the window larger.\" % fn)\n",
    "        continue\n",
    "\n",
    "    # Skip corrupted wavs\n",
    "    if sound_clip.shape[0] == 0:\n",
    "        print(\"File %s is corrupted!\" % fn)\n",
    "        continue\n",
    "\n",
    "    # Compute spectrogram\n",
    "    [f, t, x] = signal.spectral.spectrogram(\n",
    "        x=sound_clip,\n",
    "        window=ham_win,\n",
    "        nperseg=n_window,\n",
    "        noverlap=n_overlap,\n",
    "        detrend=False,\n",
    "        return_onesided=True,\n",
    "        mode='magnitude')\n",
    "    x = np.dot(x.T, melW.T)\n",
    "    x = np.log(x + 1e-8)\n",
    "    x = x.astype(np.float32).T\n",
    "    x = pad_trunc_seq_rewrite(x, frames)\n",
    "\n",
    "    log_specgrams_list.append(x)\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams_list).reshape(len(log_specgrams_list), bands, frames, 1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    features = np.concatenate((features, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    for i in range(len(features)):\n",
    "        # first order difference, computed over 9-step window\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "        # for using 3 dimensional array to use ResNet and other frameworks\n",
    "        features[i, :, :, 2] = librosa.feature.delta(features[i, :, :, 1])\n",
    "\n",
    "    return np.array(features)  #, np.array(labels, dtype=np.int)\n",
    "\n",
    "\n",
    "def init():\n",
    "    global cnn\n",
    "    model_path = Model.get_model_path(model_name = 'fannoise-predictor')\n",
    "    keras.backend.clear_session()\n",
    "    cnn = keras.models.load_model(model_path)\n",
    "\n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "    print(\"Request: [{0}]\".format(request))\n",
    "    \n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "#         file.save('temp.wav')\n",
    "#         reqBody = request.get_data(False)\n",
    "#         # reqBody to sample_audio\n",
    "#         sample_audio = reqBody\n",
    "        \n",
    "        features = extract_features(file, bands=n_bands, frames=n_frames)\n",
    "        y_prob = cnn.predict(features, verbose=0)\n",
    "        y_pred = np.argmax(y_prob, axis=-1)\n",
    "        defect_code = {2: \"Pass\", 3: \"Noise\", 4: \"Rpm\", 5: \"Vibration\"}\n",
    "        # For a real-world solution, you would load the data from reqBody\n",
    "        # and send it to the model. Then return the response.\n",
    "#         os.remove('temp.wav')\n",
    "\n",
    "        # For demonstration purposes, this example just returns the posted data as the response.\n",
    "        return AMLResponse(defect_code[int(y_pred)], 200)\n",
    "    else:\n",
    "        return AMLResponse(\"bad request\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scipy\")\n",
    "myenv.add_conda_package(\"keras\")\n",
    "myenv.add_conda_package(\"librosa\")\n",
    "myenv.add_conda_package(\"numpy\")\n",
    "\n",
    "with open(\"myenv.yml\", \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "# Use environment in InferenceConfig\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rick sample code\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import Webservice, AciWebservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"WAV\",  \n",
    "                                                     \"method\": \"keras\"},\n",
    "                                               description='Predict wav file')\n",
    "image_config = ContainerImage.image_configuration(\n",
    "    execution_script = \"score.py\",\n",
    "    runtime = \"python\",\n",
    "    conda_file = \"myenv.yml\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContainerImage(workspace=Workspace.create(name='EAP', subscription_id='b14cff6a-38c4-4aec-9335-b453f4d03339', resource_group='RG-AIEAP'), name=myimg, id=myimg:1, tags={}, properties={}, version=1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.image import Image\n",
    "Image.list(ws)\n",
    "# service = Webservice.deploy_from_image(\n",
    "#     name = \"wavprediction\",\n",
    "#     deployment_config = aci_config,\n",
    "#     image = image_config,\n",
    "#     workspace = ws\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running......................................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image wavprediction:3, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# deploy from model\n",
    "service = Webservice.deploy_from_model(\n",
    "    name = \"wavprediction\",\n",
    "    deployment_config = aci_config,\n",
    "    models = [x[1] for x in models.items()],\n",
    "    image_config = image_config,\n",
    "    workspace = ws\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Received bad response from Model Management Service:\n",
      "Response Code: 404\n",
      "Headers: {'Date': 'Thu, 31 Oct 2019 06:21:31 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '31eb66ad1feb405696dd729061aa758a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\n",
      "Content: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found\",\"details\":[{\"code\":\"ContainerLogNotAvailable\",\"message\":\"Log of container \\'wavprediction\\' in container group \\'wavprediction\\' is not available yet. Please check container \\'InstanceView\\' for more information or retry later.\"}]}'\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 404\nHeaders: {'Date': 'Thu, 31 Oct 2019 06:21:31 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '31eb66ad1feb405696dd729061aa758a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\nContent: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found\",\"details\":[{\"code\":\"ContainerLogNotAvailable\",\"message\":\"Log of container \\'wavprediction\\' in container group \\'wavprediction\\' is not available yet. Please check container \\'InstanceView\\' for more information or retry later.\"}]}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 404\\nHeaders: {'Date': 'Thu, 31 Oct 2019 06:21:31 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '31eb66ad1feb405696dd729061aa758a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\\nContent: b'{\\\"code\\\":\\\"NotFound\\\",\\\"statusCode\\\":404,\\\"message\\\":\\\"The specified resource was not found\\\",\\\"details\\\":[{\\\"code\\\":\\\"ContainerLogNotAvailable\\\",\\\"message\\\":\\\"Log of container \\\\'wavprediction\\\\' in container group \\\\'wavprediction\\\\' is not available yet. Please check container \\\\'InstanceView\\\\' for more information or retry later.\\\"}]}'\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d9b3c3bf9972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mget_logs\u001b[0;34m(self, num_lines)\u001b[0m\n\u001b[1;32m    783\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 404\nHeaders: {'Date': 'Thu, 31 Oct 2019 06:21:31 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '31eb66ad1feb405696dd729061aa758a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\nContent: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found\",\"details\":[{\"code\":\"ContainerLogNotAvailable\",\"message\":\"Log of container \\'wavprediction\\' in container group \\'wavprediction\\' is not available yet. Please check container \\'InstanceView\\' for more information or retry later.\"}]}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 404\\nHeaders: {'Date': 'Thu, 31 Oct 2019 06:21:31 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '31eb66ad1feb405696dd729061aa758a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\\nContent: b'{\\\"code\\\":\\\"NotFound\\\",\\\"statusCode\\\":404,\\\"message\\\":\\\"The specified resource was not found\\\",\\\"details\\\":[{\\\"code\\\":\\\"ContainerLogNotAvailable\\\",\\\"message\\\":\\\"Log of container \\\\'wavprediction\\\\' in container group \\\\'wavprediction\\\\' is not available yet. Please check container \\\\'InstanceView\\\\' for more information or retry later.\\\"}]}'\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: This method does not support local deployment configuration. Please use deploy_local_from_model for local deployment.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"This method does not support local deployment configuration. Please use deploy_local_from_model for local deployment.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-6a891a249ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdeploy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-6a891a249ef8>\u001b[0m in \u001b[0;36mdeploy_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdeployment_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8890\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"testservice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(workspace, name, model_paths, image_config, deployment_config, deployment_target)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[1;32m    266\u001b[0m         \u001b[0mwebservice_name_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_local_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_existing_webservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_check_for_local_deployment\u001b[0;34m(deployment_config)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocalWebserviceDeploymentConfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment_config\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mLocalWebserviceDeploymentConfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             raise WebserviceException('This method does not support local deployment configuration. Please use '\n\u001b[0m\u001b[1;32m    377\u001b[0m                                       'deploy_local_from_model for local deployment.')\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: This method does not support local deployment configuration. Please use deploy_local_from_model for local deployment.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"This method does not support local deployment configuration. Please use deploy_local_from_model for local deployment.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "def deploy_image():\n",
    "    from azureml.core import Environment\n",
    "    from azureml.core.model import InferenceConfig\n",
    "    from azureml.core.webservice import LocalWebservice, Webservice\n",
    "    \n",
    "    # Create the environment\n",
    "    myenv = Environment(name=\"myenv\")\n",
    "    # Enable Docker and reference an image\n",
    "    myenv.docker.enabled = True\n",
    "    # Set the container registry information\n",
    "    myenv.docker.base_image_registry.address = \"eap384b3414.azurecr.io/\"\n",
    "    myenv.docker.base_image_registry.username = \"V-MS.RICK.SHIH\"\n",
    "    myenv.docker.base_image_registry.password = \"!@#$%5tgb\"\n",
    "    # Use environment in InferenceConfig\n",
    "    inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                       environment=myenv)\n",
    "\n",
    "    deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "    service = Webservice.deploy(ws, \"testservice\", [x[1] for x in models.items()], inference_config, deployment_config)\n",
    "    service.wait_for_deployment(show_output = True)\n",
    "    print(service.state)\n",
    "deploy_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
