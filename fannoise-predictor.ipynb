{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAP\n",
      "RG-AIEAP\n",
      "southeastasia\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# get existing workspace\n",
    "ws = Workspace(\n",
    "    subscription_id=\"b14cff6a-38c4-4aec-9335-b453f4d03339\",\n",
    "    resource_group=\"RG-AIEAP\",\n",
    "    workspace_name=\"EAP\",\n",
    ")\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = \"delta-experiment\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '20190903080554-4415.wav',\n",
       " 'azureml-models',\n",
       " 'fannoise-predictor.ipynb',\n",
       " 'fold1',\n",
       " 'fold2',\n",
       " 'fold3',\n",
       " 'fold4',\n",
       " 'fold5',\n",
       " 'model.h5',\n",
       " 'myenv.yml',\n",
       " 'samples-1.0.69',\n",
       " 'score.py',\n",
       " 'twocategories',\n",
       " 'wav-150bands-150frames-3channel']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Model.register(model_path = \"model.h5\",\\n    model_name = \"fannoise-predictor\",\\n    description = \"delta fannoise recognotion model\",\\n    workspace = ws)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "\"\"\"\n",
    "model = Model.register(model_path = \"model.h5\",\n",
    "    model_name = \"fannoise-predictor\",\n",
    "    description = \"delta fannoise recognotion model\",\n",
    "    workspace = ws)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fannoise-predictor \n",
      "Version: 1 \n",
      "Description: delta fannoise recognotion model\n"
     ]
    }
   ],
   "source": [
    "# displaying registered models\n",
    "models = ws.models\n",
    "for name, m in models.items():\n",
    "    print(\"Name:\", name,\"\\nVersion:\", m.version, \"\\nDescription:\", m.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import signal\n",
    "\n",
    "model = Model.get_model_path(model_name = 'fannoise-predictor', _workspace = ws)\n",
    "\n",
    "sample_audio = \"20190903080554-4415.wav\"\n",
    "\n",
    "n_bands = 150\n",
    "n_frames = 150\n",
    "sample_rate = 22050\n",
    "\n",
    "\n",
    "def read_audio(audio_path, target_fs=None, duration=4):\n",
    "    (audio, fs) = librosa.load(audio_path, sr=None, duration=duration)\n",
    "    # if this is not a mono sounds file\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "    return audio, fs\n",
    "\n",
    "def pad_trunc_seq_rewrite(x, max_len):\n",
    "    if x.shape[1] < max_len:\n",
    "        pad_shape = (x.shape[0], max_len - x.shape[1])\n",
    "        pad = np.ones(pad_shape) * np.log(1e-8)\n",
    "        x_new = np.hstack((x, pad))\n",
    "    # no pad necessary - truncate\n",
    "    else:\n",
    "        x_new = x[:, 0:max_len]\n",
    "    return x_new\n",
    "\n",
    "def extract_features(parent_dir, sub_dirs, bands, frames, file_ext=\"*.wav\"):\n",
    "    # 4 second clip with 50% window overlap with small offset to guarantee frames\n",
    "    n_window = int(sample_rate * 4. / frames * 2) - 4 * 2\n",
    "    # 50% overlap\n",
    "    n_overlap = int(n_window / 2.)\n",
    "    # Mel filter bank\n",
    "    melW = librosa.filters.mel(sr=sample_rate, n_fft=n_window, n_mels=bands, fmin=0., fmax=8000.)\n",
    "    # Hamming window\n",
    "    ham_win = np.hamming(n_window)\n",
    "    log_specgrams_list = []\n",
    "\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            # print(\"processing\", fn)\n",
    "            sound_clip, fn_fs = read_audio(fn, target_fs=sample_rate)\n",
    "            assert (int(fn_fs) == sample_rate)\n",
    "\n",
    "            if sound_clip.shape[0] < n_window:\n",
    "                print(\"File %s is shorter than window size - DISCARDING - look into making the window larger.\" % fn)\n",
    "                continue\n",
    "\n",
    "            # Skip corrupted wavs\n",
    "            if sound_clip.shape[0] == 0:\n",
    "                print(\"File %s is corrupted!\" % fn)\n",
    "                continue\n",
    "\n",
    "            # Compute spectrogram\n",
    "            [f, t, x] = signal.spectral.spectrogram(\n",
    "                x=sound_clip,\n",
    "                window=ham_win,\n",
    "                nperseg=n_window,\n",
    "                noverlap=n_overlap,\n",
    "                detrend=False,\n",
    "                return_onesided=True,\n",
    "                mode='magnitude')\n",
    "            x = np.dot(x.T, melW.T)\n",
    "            x = np.log(x + 1e-8)\n",
    "            x = x.astype(np.float32).T\n",
    "            x = pad_trunc_seq_rewrite(x, frames)\n",
    "\n",
    "            log_specgrams_list.append(x)\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams_list).reshape(len(log_specgrams_list), bands, frames, 1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    features = np.concatenate((features, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    for i in range(len(features)):\n",
    "        # first order difference, computed over 9-step window\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "        # for using 3 dimensional array to use ResNet and other frameworks\n",
    "        features[i, :, :, 2] = librosa.feature.delta(features[i, :, :, 1])\n",
    "\n",
    "    return np.array(features)  #, np.array(labels, dtype=np.int)\n",
    "\n",
    "\n",
    "features = extract_features(\".\", sample_audio, bands=n_bands, frames=n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "cnn = keras.models.load_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "y_prob = cnn.predict(features, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "defect_code = {2: \"Pass\", 3: \"Noise\", 4: \"Rpm\", 5: \"Vibration\"}\n",
    "\n",
    "print(defect_code[int(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "from azureml.core.model import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "n_bands = 150\n",
    "n_frames = 150\n",
    "sample_rate = 22050\n",
    "\n",
    "\n",
    "def read_audio(audio_path, target_fs=None, duration=4):\n",
    "    (audio, fs) = librosa.load(audio_path, sr=None, duration=duration)\n",
    "    # if this is not a mono sounds file\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "    return audio, fs\n",
    "\n",
    "def pad_trunc_seq_rewrite(x, max_len):\n",
    "    if x.shape[1] < max_len:\n",
    "        pad_shape = (x.shape[0], max_len - x.shape[1])\n",
    "        pad = np.ones(pad_shape) * np.log(1e-8)\n",
    "        x_new = np.hstack((x, pad))\n",
    "    # no pad necessary - truncate\n",
    "    else:\n",
    "        x_new = x[:, 0:max_len]\n",
    "    return x_new\n",
    "\n",
    "def extract_features(sample_audio, bands, frames, file_ext=\"*.wav\"):\n",
    "    # 4 second clip with 50% window overlap with small offset to guarantee frames\n",
    "    n_window = int(sample_rate * 4. / frames * 2) - 4 * 2\n",
    "    # 50% overlap\n",
    "    n_overlap = int(n_window / 2.)\n",
    "    # Mel filter bank\n",
    "    melW = librosa.filters.mel(sr=sample_rate, n_fft=n_window, n_mels=bands, fmin=0., fmax=8000.)\n",
    "    # Hamming window\n",
    "    ham_win = np.hamming(n_window)\n",
    "    log_specgrams_list = []\n",
    "\n",
    "\n",
    "    sound_clip, fn_fs = read_audio(sample_audio, target_fs=sample_rate)\n",
    "    assert (int(fn_fs) == sample_rate)\n",
    "\n",
    "    if sound_clip.shape[0] < n_window:\n",
    "        print(\"File %s is shorter than window size - DISCARDING - look into making the window larger.\" % fn)\n",
    "\n",
    "    # Skip corrupted wavs\n",
    "    if sound_clip.shape[0] == 0:\n",
    "        print(\"File %s is corrupted!\" % fn)\n",
    "\n",
    "    # Compute spectrogram\n",
    "    [f, t, x] = signal.spectral.spectrogram(\n",
    "        x=sound_clip,\n",
    "        window=ham_win,\n",
    "        nperseg=n_window,\n",
    "        noverlap=n_overlap,\n",
    "        detrend=False,\n",
    "        return_onesided=True,\n",
    "        mode='magnitude')\n",
    "    x = np.dot(x.T, melW.T)\n",
    "    x = np.log(x + 1e-8)\n",
    "    x = x.astype(np.float32).T\n",
    "    x = pad_trunc_seq_rewrite(x, frames)\n",
    "\n",
    "    log_specgrams_list.append(x)\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams_list).reshape(len(log_specgrams_list), bands, frames, 1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    features = np.concatenate((features, np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "    for i in range(len(features)):\n",
    "        # first order difference, computed over 9-step window\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "        # for using 3 dimensional array to use ResNet and other frameworks\n",
    "        features[i, :, :, 2] = librosa.feature.delta(features[i, :, :, 1])\n",
    "\n",
    "    return np.array(features)  #, np.array(labels, dtype=np.int)\n",
    "\n",
    "\n",
    "def init():\n",
    "    global cnn\n",
    "    model_path = Model.get_model_path(model_name = 'fannoise-predictor')\n",
    "    keras.backend.clear_session()\n",
    "    cnn = keras.models.load_model(model_path)\n",
    "\n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "    print(\"Request: [{0}]\".format(request))\n",
    "    \n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "#         file.save('temp.wav')\n",
    "#         reqBody = request.get_data(False)\n",
    "#         # reqBody to sample_audio\n",
    "#         sample_audio = reqBody\n",
    "        \n",
    "        features = extract_features(file, bands=n_bands, frames=n_frames)\n",
    "        y_prob = cnn.predict(features, verbose=0)\n",
    "        y_pred = np.argmax(y_prob, axis=-1)\n",
    "        defect_code = {2: \"Pass\", 3: \"Noise\", 4: \"Rpm\", 5: \"Vibration\"}\n",
    "        # For a real-world solution, you would load the data from reqBody\n",
    "        # and send it to the model. Then return the response.\n",
    "#         os.remove('temp.wav')\n",
    "\n",
    "        # For demonstration purposes, this example just returns the posted data as the response.\n",
    "        return AMLResponse(defect_code[int(y_pred)], 200)\n",
    "    else:\n",
    "        return AMLResponse(\"bad request\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scipy\")\n",
    "myenv.add_conda_package(\"keras\")\n",
    "myenv.add_conda_package(\"librosa\")\n",
    "myenv.add_conda_package(\"numpy\")\n",
    "myenv.add_conda_package(\"tensorflow\")\n",
    "\n",
    "with open(\"myenv.yml\", \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CondaDependencies' object has no attribute 'python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-47743b6d84d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Use environment in InferenceConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m inference_config = InferenceConfig(entry_script=\"score.py\",\n\u001b[0;32m----> 4\u001b[0;31m                                    environment=myenv)\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, entry_script, runtime, conda_file, extra_docker_file_steps, source_directory, enable_gpu, description, base_image, base_image_registry, cuda_version, environment)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mvalidate_configuration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1662\u001b[0m                                           'enable_gpu, cuda_version, or base_image along with an environment object.')\n\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m'azureml-defaults'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconda_dependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m                 module_logger.warning('Warning, azureml-defaults not detected in provided environment pip '\n\u001b[1;32m   1666\u001b[0m                                       \u001b[0;34m'dependencies. The azureml-defaults package contains requirements for the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CondaDependencies' object has no attribute 'python'"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "# Use environment in InferenceConfig\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rick sample code\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import Webservice, AciWebservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"WAV\",  \n",
    "                                                     \"method\": \"keras\"},\n",
    "                                               description='Predict wav file')\n",
    "image_config = ContainerImage.image_configuration(\n",
    "    execution_script = \"score.py\",\n",
    "    runtime = \"python\",\n",
    "    conda_file = \"myenv.yml\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.................................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image myimg:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Create the image\n",
    "image = Image.create(name='myimg', models=[x[1] for x in models.items()], image_config=image_config, workspace=ws)\n",
    "\n",
    "# wait for image creation to finish\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running....................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# deploy from image\n",
    "from azureml.core.image import Image\n",
    "image = Image(ws, name ='myimg')\n",
    "service = Webservice.deploy_from_image(\n",
    "    name = \"wavprediction\",\n",
    "    deployment_config = aci_config,\n",
    "    image = image,\n",
    "    workspace = ws\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-31T08:02:05,723940013+00:00 - iot-server/run \n",
      "2019-10-31T08:02:05,725245716+00:00 - rsyslog/run \n",
      "2019-10-31T08:02:05,724776215+00:00 - gunicorn/run \n",
      "2019-10-31T08:02:05,869791169+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2019-10-31T08:02:09,550673338+00:00 - iot-server/finish 1 0\n",
      "2019-10-31T08:02:09,553460344+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 45\n",
      "generated new fontManager\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-10-31 08:02:21,704 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}, switching offline: False\n",
      "2019-10-31 08:02:21,704 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-10-31 08:02:21,705 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}\n",
      "2019-10-31 08:02:21,705 | azureml.core.model | DEBUG | version is None. Latest version is 1\n",
      "2019-10-31 08:02:21,705 | azureml.core.model | DEBUG | Found model path at azureml-models/fannoise-predictor/1/model.h5\n",
      "From /opt/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-10-31 08:02:21.896259: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-10-31 08:02:21.903016: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394450000 Hz\n",
      "2019-10-31 08:02:21.903217: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a955cd1200 executing computations on platform Host. Devices:\n",
      "2019-10-31 08:02:21.903275: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "From /opt/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Using TensorFlow backend.\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update score.py to service\n",
    "service.update(inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-c86fb71dea2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test service with sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_sample' is not defined"
     ]
    }
   ],
   "source": [
    "# test service with sample\n",
    "test_sample = bytes(test_sample, encoding='utf8')\n",
    "\n",
    "prediction = service.run(input_data=test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
